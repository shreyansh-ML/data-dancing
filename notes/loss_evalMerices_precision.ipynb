{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html\n",
    "1.Cross Entropy log loss -- classification\n",
    "2.hinge -- classification\n",
    "3.huber -- regression\n",
    "4.Kullback-Leibler -- \n",
    "5.MAE [l1]\n",
    "5.MSE [l2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy - log loss\n",
    "for binar classification:\n",
    "  −(ylog(p)+(1−y)log(1−p))\n",
    "    it is derivation of sigmoid function .\n",
    "    \n",
    " for multiclass :\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "sensitivity,specificity,precision,recall               \n",
    "\n",
    "sensitivity or True Positive Rate or recall = true positive / tp+fn\n",
    "\n",
    "Specificity = True Negatives / (True Negatives + False Positives) \n",
    "\n",
    "precision=tp/tp+fp\n",
    "\n",
    "recall=tp/tp+fn\n",
    "\n",
    "fp rate=fp/fp+tn\n",
    "False Positive Rate = 1 - Specificity\n",
    "False Positive Rate = False Positives / (False Positives + True Negatives) #false alarm rate ,inverted specificity\n",
    "ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets.\n",
    "ROC is a plot of the false positive rate (x-axis) versus the true positive rate (y-axis) for a number of different candidate threshold values between 0.0 and 1.0\n",
    "\n",
    "When we decrease the threshold, we get more positive values thus increasing the sensitivity. Meanwhile, this will decrease the specificity.\n",
    "https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n",
    "AUC is scale-invariant.\n",
    "AUC is classification-threshold-invariant.\n",
    "\n",
    "---\n",
    "However, both these reasons come with caveats, which may limit the usefulness of AUC in certain use cases:\n",
    "\n",
    "Scale invariance is not always desirable. For example, sometimes we really do need well calibrated probability outputs, and AUC won’t tell us about that.\n",
    "\n",
    "Classification-threshold invariance is not always desirable. In cases where there are wide disparities in the cost of false negatives vs. false positives, it may be critical to minimize one type of classification error. For example, when doing email spam detection, you likely want to prioritize minimizing false positives (even if that results in a significant increase of false negatives). AUC isn't a useful metric for this type of optimization.\n",
    "\n",
    "AUC is based on the relative predictions, so any transformation of the predictions that preserves the relative ranking has no effect on AUC. This is clearly not the case for other metrics such as squared error, log loss, or prediction bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_np,y_pred, pos_label=2)\n",
    "pre,rec,thold=metrices.precision_recall_curve(actual_label,probality/decision fn score)\n",
    "\n",
    "look at following:\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
