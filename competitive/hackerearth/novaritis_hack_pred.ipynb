{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\",parse_dates=[1])\n",
    "#df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"test.csv\",parse_dates=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X_12'], dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns[df_test.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23674.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "      <td>23856.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.483778</td>\n",
       "      <td>24.791206</td>\n",
       "      <td>24.637450</td>\n",
       "      <td>4.276744</td>\n",
       "      <td>2.455609</td>\n",
       "      <td>6.154175</td>\n",
       "      <td>4.876509</td>\n",
       "      <td>0.972460</td>\n",
       "      <td>4.924128</td>\n",
       "      <td>1.244802</td>\n",
       "      <td>206.954519</td>\n",
       "      <td>0.974064</td>\n",
       "      <td>85.237383</td>\n",
       "      <td>72.674296</td>\n",
       "      <td>33.464747</td>\n",
       "      <td>0.955231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.439738</td>\n",
       "      <td>15.240231</td>\n",
       "      <td>15.135093</td>\n",
       "      <td>2.944672</td>\n",
       "      <td>1.963095</td>\n",
       "      <td>4.471756</td>\n",
       "      <td>3.881931</td>\n",
       "      <td>1.453144</td>\n",
       "      <td>1.362625</td>\n",
       "      <td>1.119301</td>\n",
       "      <td>93.033348</td>\n",
       "      <td>1.167725</td>\n",
       "      <td>27.597226</td>\n",
       "      <td>43.297320</td>\n",
       "      <td>8.386834</td>\n",
       "      <td>0.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X_1           X_2           X_3           X_4           X_5  \\\n",
       "count  23856.000000  23856.000000  23856.000000  23856.000000  23856.000000   \n",
       "mean       0.483778     24.791206     24.637450      4.276744      2.455609   \n",
       "std        1.439738     15.240231     15.135093      2.944672      1.963095   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      7.000000      8.000000      2.000000      1.000000   \n",
       "50%        0.000000     24.000000     24.000000      4.000000      3.000000   \n",
       "75%        0.000000     36.000000     35.000000      6.000000      5.000000   \n",
       "max        7.000000     52.000000     52.000000     10.000000      5.000000   \n",
       "\n",
       "                X_6           X_7           X_8           X_9          X_10  \\\n",
       "count  23856.000000  23856.000000  23856.000000  23856.000000  23856.000000   \n",
       "mean       6.154175      4.876509      0.972460      4.924128      1.244802   \n",
       "std        4.471756      3.881931      1.453144      1.362625      1.119301   \n",
       "min        1.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "25%        3.000000      2.000000      0.000000      5.000000      1.000000   \n",
       "50%        5.000000      4.000000      1.000000      5.000000      1.000000   \n",
       "75%        8.000000      7.000000      1.000000      6.000000      1.000000   \n",
       "max       19.000000     18.000000     99.000000      6.000000     90.000000   \n",
       "\n",
       "               X_11          X_12          X_13          X_14          X_15  \\\n",
       "count  23856.000000  23674.000000  23856.000000  23856.000000  23856.000000   \n",
       "mean     206.954519      0.974064     85.237383     72.674296     33.464747   \n",
       "std       93.033348      1.167725     27.597226     43.297320      8.386834   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      174.000000      1.000000     72.000000     29.000000     34.000000   \n",
       "50%      249.000000      1.000000     98.000000     62.000000     34.000000   \n",
       "75%      249.000000      1.000000    103.000000    107.000000     34.000000   \n",
       "max      332.000000     90.000000    116.000000    142.000000     50.000000   \n",
       "\n",
       "       MULTIPLE_OFFENSE  \n",
       "count      23856.000000  \n",
       "mean           0.955231  \n",
       "std            0.206800  \n",
       "min            0.000000  \n",
       "25%            1.000000  \n",
       "50%            1.000000  \n",
       "75%            1.000000  \n",
       "max            1.000000  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_13</th>\n",
       "      <th>X_14</th>\n",
       "      <th>X_15</th>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR_102659</td>\n",
       "      <td>2004-07-04</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CR_189752</td>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103</td>\n",
       "      <td>142</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CR_184637</td>\n",
       "      <td>2017-03-15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CR_139071</td>\n",
       "      <td>2009-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CR_109335</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  INCIDENT_ID       DATE  X_1  X_2  X_3  X_4  X_5  X_6  X_7  X_8  X_9  X_10  \\\n",
       "0   CR_102659 2004-07-04    0   36   34    2    1    5    6    1    6     1   \n",
       "1   CR_189752 2017-07-18    1   37   37    0    0   11   17    1    6     1   \n",
       "2   CR_184637 2017-03-15    0    3    2    3    5    1    0    2    3     1   \n",
       "3   CR_139071 2009-02-13    0   33   32    2    1    7    1    1    6     1   \n",
       "4   CR_109335 2005-04-13    0   33   32    2    1    8    3    0    5     1   \n",
       "\n",
       "   X_11  X_12  X_13  X_14  X_15  MULTIPLE_OFFENSE  \n",
       "0   174   1.0    92    29    36                 0  \n",
       "1   236   1.0   103   142    34                 1  \n",
       "2   174   1.0   110    93    34                 1  \n",
       "3   249   1.0    72    29    34                 1  \n",
       "4   174   0.0   112    29    43                 1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23856 entries, 0 to 23855\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   INCIDENT_ID       23856 non-null  object        \n",
      " 1   DATE              23856 non-null  datetime64[ns]\n",
      " 2   X_1               23856 non-null  int64         \n",
      " 3   X_2               23856 non-null  int64         \n",
      " 4   X_3               23856 non-null  int64         \n",
      " 5   X_4               23856 non-null  int64         \n",
      " 6   X_5               23856 non-null  int64         \n",
      " 7   X_6               23856 non-null  int64         \n",
      " 8   X_7               23856 non-null  int64         \n",
      " 9   X_8               23856 non-null  int64         \n",
      " 10  X_9               23856 non-null  int64         \n",
      " 11  X_10              23856 non-null  int64         \n",
      " 12  X_11              23856 non-null  int64         \n",
      " 13  X_12              23674 non-null  float64       \n",
      " 14  X_13              23856 non-null  int64         \n",
      " 15  X_14              23856 non-null  int64         \n",
      " 16  X_15              23856 non-null  int64         \n",
      " 17  MULTIPLE_OFFENSE  23856 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(15), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64             15\n",
       "float64            1\n",
       "datetime64[ns]     1\n",
       "object             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "SI=SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SI.fit(df[['X_12']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['X_12']=SI.transform(df[['X_12']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['X_12']=SI.transform(df_test[['X_12']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns[df_test.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df):\n",
    "    columns1=list([df.columns])\n",
    "    unique_values=[]\n",
    "    null_values=[]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        unique_values.append(df[col].nunique())\n",
    "        null_values.append(df[col].isnull().sum())\n",
    "        \n",
    "    df_summary=pd.DataFrame([columns1,unique_values,null_values],columns=['col_name,unique_val,null_val'])\n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_summary=summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['DATE','MULTIPLE_OFFENSE','INCIDENT_ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inident_id=df_test['INCIDENT_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.drop(columns=['DATE','INCIDENT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['MULTIPLE_OFFENSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "ss.fit(X)\n",
    "X_cols=list(X.columns)\n",
    "X=ss.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33602492,  0.73548947,  0.61861178, ...,  0.24505213,\n",
       "        -1.00872781,  0.30229601],\n",
       "       [ 0.35856051,  0.80110665,  0.81683078, ...,  0.64365126,\n",
       "         1.60118818,  0.06382199],\n",
       "       [-0.33602492, -1.42987743, -1.4957242 , ...,  0.89730526,\n",
       "         0.46945469,  0.06382199],\n",
       "       ...,\n",
       "       [-0.33602492,  0.0137005 ,  0.02395479, ..., -2.72632324,\n",
       "        -1.00872781, -1.84397015],\n",
       "       [-0.33602492,  0.932341  ,  0.94897678, ...,  0.96977783,\n",
       "         0.70042071,  1.13695506],\n",
       "       [ 4.52607309,  0.73548947,  0.61861178, ...,  0.24505213,\n",
       "        -1.00872781,  0.06382199]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_test=StandardScaler()\n",
    "ss_test.fit(df_test)\n",
    "df_cols=list(df.columns)\n",
    "df_test=ss_test.transform(df_test)\n",
    "#df_test=ss.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33149102,  0.3465487 ,  0.68916296, ..., -0.47981008,\n",
       "         1.07699829, -1.25362   ],\n",
       "       [-0.33149102,  1.26588593,  1.28412657, ..., -2.66223712,\n",
       "        -0.99497464,  0.06944597],\n",
       "       [-0.33149102,  0.60921648,  0.55694882, ..., -0.47981008,\n",
       "        -1.66261037,  0.06944597],\n",
       "       ...,\n",
       "       [-0.33149102,  0.08388092,  0.16030642, ..., -0.47981008,\n",
       "        -0.23525123,  0.06944597],\n",
       "       [-0.33149102, -0.2444538 , -0.10412185, ...,  0.2476656 ,\n",
       "        -0.23525123,  0.06944597],\n",
       "       [-0.33149102, -1.36079186, -1.36015614, ..., -0.47981008,\n",
       "        -0.99497464,  0.06944597]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=42)\n",
    "X, y = oversample.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.1 \n",
    "noise = np.random.normal(mu, sigma, [X.shape[0],X.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noise=X+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noise_train,X_noise_test,X_train_enc,X_test_enc=train_test_split(X_noise,X,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2)\n",
    "#X_val,X_test,y_val,y_test=train_test_split(X_test,y_test,test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val,X_test,y_val,y_test=train_test_split(X_test,y_test,test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB_model=Grid_XGB.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearchXGBC(X_train,y_train,lr=.3,trees=50,cv=10):\n",
    "    #XGB_classifier_param={'learning_rate':learning_rate_val,'subsample':subsample_val,'colsample_bytree':colsample_bytree_val}\n",
    "    base_XGBC=XGBClassifier(objective='binary:logistic',eval_metric='auc',booster='gbtree',n_estimators=trees,silent=0,learning_rate=lr,min_child_weight=1,max_depth=6,gamma=0,max_delta_setp=0,colsample_bytree=1)\n",
    "    #max_depth_val=[100]\n",
    "    max_depth_val=[10,30,50,70,90,20]\n",
    "    #min_child_weight_val=[1]\n",
    "    min_child_weight_val=[1,2,4,8] #equivalent of min_child_leaf in GBM\n",
    "    #eta=learning_rate\n",
    "    first_tuning={'max_depth':max_depth_val,'min_child_weight':min_child_weight_val}\n",
    "    grid_model=GridSearchCV(estimator=base_XGBC,param_grid=first_tuning,cv=cv)\n",
    "    grid_model.fit(X_train,y_train)\n",
    "    #learning-rate=2-10/num of trees\n",
    "    learning_rate_val=[.2,.1,.05,.02,.01]\n",
    "    #learning_rate_val=[.2,.1]\n",
    "    n_estimators_val=[50,100,200,400,500,800,1000]\n",
    "    #n_estimators_val=[100,200]\n",
    "    second_tuning={'learning_rate':learning_rate_val,'n_estimators':n_estimators_val}\n",
    "    final_model=GridSearchCV(estimator=grid_model.best_estimator_,param_grid=second_tuning,cv=cv)\n",
    "    final_model.fit(X_train,y_train)\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid_XGB=GridSearchXGBC(X_train,y_train,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model=Grid_XGB.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(eval_metric='auc', learning_rate=0.05, max_delta_setp=0,\n",
       "              max_depth=30, n_estimators=800, silent=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pred=XGB_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_upload=rfc.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33602492, -0.44561975, -0.43855621, ...,  0.64365126,\n",
       "         1.60118818,  0.06382199],\n",
       "       [-0.33602492,  0.99795818,  1.01504978, ...,  0.64365126,\n",
       "         0.46945469,  0.06382199],\n",
       "       [-0.33602492,  1.2604269 ,  1.27934178, ..., -1.8566524 ,\n",
       "        -1.00872781, -3.9902363 ],\n",
       "       ...,\n",
       "       [-0.33602492, -0.11753386, -0.24033721, ..., -2.65385067,\n",
       "         0.16919887,  0.06382199],\n",
       "       [-0.33602492, -0.44561975, -0.43855621, ...,  0.64365126,\n",
       "        -1.00872781,  0.06382199],\n",
       "       [ 0.35856051, -0.57685411, -0.63677521, ...,  0.06387071,\n",
       "         1.60118818,  0.06382199]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19084, 15)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network=models.Sequential()\n",
    "network.add(layers.Dense(512,activation='relu',name='layer1',input_shape=(15,)))\n",
    "network.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datadict={'INCIDENT_ID':test_inident_id,'MULTIPLE_OFFENSE':y_nn_pred[:,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datadict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-58179f41478b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mupload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatadict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'datadict' is not defined"
     ]
    }
   ],
   "source": [
    "#upload=pd.DataFrame(data=datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload.to_csv(\"hacking_incidence_NN2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import optimizers,initializers,activations\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "#from keras import lecun_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.initializers.Initializer at 0x204779342c8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initializers.Initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq=Sequential()\n",
    "seq.add(16,kernel_initializer=tf.keras.initializers.lecun_uniform,activation='elu',input_shape=(),name='layer1')\n",
    "#seq.add(8,kernel_initializer='lecun_uniform',activation='elu',name='layer2')\n",
    "#seq.add(4,kernel_initializer='lecun_uniform',activation='elu',name='layer3')\n",
    "seq.add(1,kernel_initializer='glorot_uniform',activation='sigmoid',name='layer4')\n",
    "#seq.compile(optimizer=optimizers.RMSprop(lr=0.001),loss=losses.binary_crossentropy,metrics=[metrics.binary_accuracy])\n",
    "#history = model.fit(X_train, y_train, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq=Sequential()\n",
    "seq.add(Dense(32,activation=activations.relu,input_shape=(15,),name='layer1'))\n",
    "seq.add(layers.Dropout(0.5))\n",
    "seq.add(Dense(64,activation=activations.relu,input_shape=(15,),name='layer1_1'))\n",
    "seq.add(layers.Dropout(0.5))\n",
    "seq.add(Dense(128,activation=activations.relu,input_shape=(15,),name='layer1_2'))\n",
    "seq.add(layers.Dropout(0.5))\n",
    "seq.add(Dense(64,activation=activations.relu,input_shape=(15,),name='layer1_3'))\n",
    "seq.add(layers.Dropout(0.5))\n",
    "seq.add(Dense(32,activation=activations.relu,input_shape=(15,),name='layer1_4'))\n",
    "seq.add(layers.Dropout(0.5))\n",
    "seq.add(Dense(16,activation=activations.relu,input_shape=(15,),name='layer1_5'))\n",
    "seq.add(layers.Dropout(0.5))\n",
    "seq.add(Dense(8,activation=activations.relu,name='layer2'))\n",
    "seq.add(layers.Dropout(0.5))\n",
    "seq.add(Dense(4,activation='elu',name='layer3'))\n",
    "seq.add(Dense(1,activation='sigmoid',name='layer4'))\n",
    "seq.compile(optimizer=optimizers.RMSprop(lr=0.001),loss=losses.binary_crossentropy,metrics=[metrics.binary_accuracy])\n",
    "history = seq.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 18213 (95.44% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(val)\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(y_train)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001148105625717566"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_for_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19084 samples, validate on 2386 samples\n",
      "Epoch 1/50\n",
      "19084/19084 [==============================] - 1s 62us/step - loss: 8.3520e-04 - recall: 0.0535 - val_loss: 1.8751 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "19084/19084 [==============================] - 1s 36us/step - loss: 3.6538e-04 - recall: 0.0000e+00 - val_loss: 2.3596 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "19084/19084 [==============================] - 1s 36us/step - loss: 2.9297e-04 - recall: 0.0000e+00 - val_loss: 1.6909 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "19084/19084 [==============================] - 1s 36us/step - loss: 2.5135e-04 - recall: 0.0000e+00 - val_loss: 1.2822 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "19084/19084 [==============================] - 1s 43us/step - loss: 2.3787e-04 - recall: 0.0000e+00 - val_loss: 1.6052 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "19084/19084 [==============================] - 1s 63us/step - loss: 2.2042e-04 - recall: 0.0000e+00 - val_loss: 1.2234 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "19084/19084 [==============================] - 1s 46us/step - loss: 2.1494e-04 - recall: 0.0000e+00 - val_loss: 1.4216 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "19084/19084 [==============================] - 1s 44us/step - loss: 2.0687e-04 - recall: 0.0000e+00 - val_loss: 1.1831 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "19084/19084 [==============================] - 1s 68us/step - loss: 2.0434e-04 - recall: 0.0298 - val_loss: 1.3693 - val_recall: 0.2679\n",
      "Epoch 10/50\n",
      "19084/19084 [==============================] - 1s 45us/step - loss: 1.8183e-04 - recall: 0.4849 - val_loss: 1.2161 - val_recall: 0.7946\n",
      "Epoch 11/50\n",
      "19084/19084 [==============================] - 1s 37us/step - loss: 1.6470e-04 - recall: 0.7068 - val_loss: 0.8152 - val_recall: 0.8352\n",
      "Epoch 12/50\n",
      "19084/19084 [==============================] - 1s 58us/step - loss: 2.1960e-04 - recall: 0.6089 - val_loss: 1.3739 - val_recall: 0.2797\n",
      "Epoch 13/50\n",
      "19084/19084 [==============================] - 1s 49us/step - loss: 2.2138e-04 - recall: 0.3362 - val_loss: 0.8852 - val_recall: 0.6525\n",
      "Epoch 14/50\n",
      "19084/19084 [==============================] - 1s 38us/step - loss: 2.0866e-04 - recall: 0.6045 - val_loss: 1.0701 - val_recall: 0.4838\n",
      "Epoch 15/50\n",
      "19084/19084 [==============================] - 1s 53us/step - loss: 2.1556e-04 - recall: 0.4099 - val_loss: 1.0738 - val_recall: 0.5118\n",
      "Epoch 16/50\n",
      "19084/19084 [==============================] - 1s 55us/step - loss: 1.6769e-04 - recall: 0.6142 - val_loss: 0.9262 - val_recall: 0.7627\n",
      "Epoch 17/50\n",
      "19084/19084 [==============================] - 1s 39us/step - loss: 2.8516e-04 - recall: 0.4554 - val_loss: 1.4151 - val_recall: 0.0883\n",
      "Epoch 18/50\n",
      "19084/19084 [==============================] - 1s 46us/step - loss: 3.3759e-04 - recall: 0.0301 - val_loss: 2.6255 - val_recall: 0.0358\n",
      "Epoch 19/50\n",
      "19084/19084 [==============================] - 1s 60us/step - loss: 2.9308e-04 - recall: 0.1175 - val_loss: 1.2475 - val_recall: 0.3304\n",
      "Epoch 20/50\n",
      "19084/19084 [==============================] - 1s 39us/step - loss: 2.2797e-04 - recall: 0.4369 - val_loss: 1.1024 - val_recall: 0.5878\n",
      "Epoch 21/50\n",
      "19084/19084 [==============================] - 1s 41us/step - loss: 1.9670e-04 - recall: 0.5180 - val_loss: 0.9871 - val_recall: 0.6442\n",
      "Epoch 22/50\n",
      "19084/19084 [==============================] - 1s 62us/step - loss: 3.2186e-04 - recall: 0.5422 - val_loss: 1.7205 - val_recall: 0.5052\n",
      "Epoch 23/50\n",
      "19084/19084 [==============================] - 1s 45us/step - loss: 2.2670e-04 - recall: 0.4894 - val_loss: 0.8169 - val_recall: 0.5765\n",
      "Epoch 24/50\n",
      "19084/19084 [==============================] - 1s 39us/step - loss: 2.1273e-04 - recall: 0.5487 - val_loss: 0.7402 - val_recall: 0.5699\n",
      "Epoch 25/50\n",
      "19084/19084 [==============================] - 1s 58us/step - loss: 2.0241e-04 - recall: 0.5469 - val_loss: 1.4147 - val_recall: 0.6211\n",
      "Epoch 26/50\n",
      "19084/19084 [==============================] - 1s 52us/step - loss: 2.0221e-04 - recall: 0.6190 - val_loss: 0.9020 - val_recall: 0.7194\n",
      "Epoch 27/50\n",
      "19084/19084 [==============================] - 1s 39us/step - loss: 2.0822e-04 - recall: 0.6580 - val_loss: 0.7249 - val_recall: 0.5481\n",
      "Epoch 28/50\n",
      "19084/19084 [==============================] - 1s 55us/step - loss: 5.1219e-04 - recall: 0.3334 - val_loss: 1.3383 - val_recall: 0.2653\n",
      "Epoch 29/50\n",
      "19084/19084 [==============================] - 1s 54us/step - loss: 2.8867e-04 - recall: 0.2790 - val_loss: 1.2165 - val_recall: 0.4873\n",
      "Epoch 30/50\n",
      "19084/19084 [==============================] - 1s 38us/step - loss: 4.4912e-04 - recall: 0.2978 - val_loss: 1.5144 - val_recall: 0.3011\n",
      "Epoch 31/50\n",
      "19084/19084 [==============================] - 1s 50us/step - loss: 3.0394e-04 - recall: 0.2907 - val_loss: 1.2769 - val_recall: 0.3837\n",
      "Epoch 32/50\n",
      "19084/19084 [==============================] - 1s 58us/step - loss: 9.2476e-04 - recall: 0.3992 - val_loss: 1.7806 - val_recall: 0.1718\n",
      "Epoch 33/50\n",
      "19084/19084 [==============================] - 1s 39us/step - loss: 3.1898e-04 - recall: 0.0732 - val_loss: 1.7671 - val_recall: 0.0555\n",
      "Epoch 34/50\n",
      "19084/19084 [==============================] - 1s 42us/step - loss: 3.0124e-04 - recall: 0.0667 - val_loss: 1.2428 - val_recall: 0.2286\n",
      "Epoch 35/50\n",
      "19084/19084 [==============================] - 1s 62us/step - loss: 2.5305e-04 - recall: 0.2977 - val_loss: 1.2693 - val_recall: 0.5581\n",
      "Epoch 36/50\n",
      "19084/19084 [==============================] - 1s 46us/step - loss: 5.8833e-04 - recall: 0.3876 - val_loss: 1.6657 - val_recall: 0.2207\n",
      "Epoch 37/50\n",
      "19084/19084 [==============================] - 1s 44us/step - loss: 3.5219e-04 - recall: 0.1891 - val_loss: 1.1360 - val_recall: 0.3142\n",
      "Epoch 38/50\n",
      "19084/19084 [==============================] - 1s 67us/step - loss: 6.2440e-04 - recall: 0.3489 - val_loss: 1.5630 - val_recall: 0.6154\n",
      "Epoch 39/50\n",
      "19084/19084 [==============================] - 1s 45us/step - loss: 5.2618e-04 - recall: 0.4632 - val_loss: 2.1062 - val_recall: 0.6014\n",
      "Epoch 40/50\n",
      "19084/19084 [==============================] - 1s 38us/step - loss: 3.6931e-04 - recall: 0.4593 - val_loss: 0.8114 - val_recall: 0.5433\n",
      "Epoch 41/50\n",
      "19084/19084 [==============================] - 1s 57us/step - loss: 3.2742e-04 - recall: 0.4325 - val_loss: 1.4750 - val_recall: 0.5682\n",
      "Epoch 42/50\n",
      "19084/19084 [==============================] - 1s 50us/step - loss: 3.2006e-04 - recall: 0.4822 - val_loss: 1.0915 - val_recall: 0.5948\n",
      "Epoch 43/50\n",
      "19084/19084 [==============================] - 1s 37us/step - loss: 3.4772e-04 - recall: 0.4864 - val_loss: 1.2909 - val_recall: 0.4397\n",
      "Epoch 44/50\n",
      "19084/19084 [==============================] - 1s 50us/step - loss: 3.0191e-04 - recall: 0.1934 - val_loss: 1.2983 - val_recall: 0.2985\n",
      "Epoch 45/50\n",
      "19084/19084 [==============================] - 1s 56us/step - loss: 2.8010e-04 - recall: 0.2399 - val_loss: 1.0201 - val_recall: 0.5017\n",
      "Epoch 46/50\n",
      "19084/19084 [==============================] - 1s 37us/step - loss: 2.8495e-04 - recall: 0.3941 - val_loss: 1.2933 - val_recall: 0.5516\n",
      "Epoch 47/50\n",
      "19084/19084 [==============================] - 1s 44us/step - loss: 2.7059e-04 - recall: 0.3987 - val_loss: 1.5141 - val_recall: 0.5184\n",
      "Epoch 48/50\n",
      "19084/19084 [==============================] - 1s 61us/step - loss: 3.2543e-04 - recall: 0.4942 - val_loss: 0.7881 - val_recall: 0.7067\n",
      "Epoch 49/50\n",
      "19084/19084 [==============================] - 1s 39us/step - loss: 7.2624e-04 - recall: 0.5128 - val_loss: 1.4581 - val_recall: 0.3737\n",
      "Epoch 50/50\n",
      "19084/19084 [==============================] - 1s 37us/step - loss: 4.5630e-04 - recall: 0.2841 - val_loss: 1.1690 - val_recall: 0.2915\n"
     ]
    }
   ],
   "source": [
    "seq=Sequential()\n",
    "seq.add(Dense(256,activation=activations.relu,input_shape=(15,),name='layer1'))\n",
    "seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer2'))\n",
    "seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer3'))\n",
    "seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer4'))\n",
    "seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer5'))\n",
    "seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer6'))\n",
    "seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(1,activation='sigmoid',name='layer7'))\n",
    "metrics=[keras.metrics.Recall(name=\"recall\")]\n",
    "\n",
    "seq.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics)\n",
    "class_weight = {0: .1, 1: .0001}\n",
    "\n",
    "history=seq.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=50,batch_size=2048,class_weight=class_weight)\n",
    "#history=seq.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=30,batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_NN_matrix(history,value='loss'):\n",
    "    if value == 'loss':\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "        epochs = range(1, len(loss) + 1)\n",
    "        plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        #plt.clf()\n",
    "    if value == 'acc':\n",
    "        acc = history.history['binary_accuracy']\n",
    "        val_acc = history.history['val_binary_accuracy']\n",
    "        epochs = range(1, len(acc) + 1)\n",
    "        plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "        plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_NN_matrix(history,value='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_recall', 'loss', 'recall'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33149102,  0.3465487 ,  0.68916296, ..., -0.47981008,\n",
       "         1.07699829, -1.25362   ],\n",
       "       [-0.33149102,  1.26588593,  1.28412657, ..., -2.66223712,\n",
       "        -0.99497464,  0.06944597],\n",
       "       [-0.33149102,  0.60921648,  0.55694882, ..., -0.47981008,\n",
       "        -1.66261037,  0.06944597],\n",
       "       ...,\n",
       "       [-0.33149102,  0.08388092,  0.16030642, ..., -0.47981008,\n",
       "        -0.23525123,  0.06944597],\n",
       "       [-0.33149102, -0.2444538 , -0.10412185, ...,  0.2476656 ,\n",
       "        -0.23525123,  0.06944597],\n",
       "       [-0.33149102, -1.36079186, -1.36015614, ..., -0.47981008,\n",
       "        -0.99497464,  0.06944597]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.0\n"
     ]
    }
   ],
   "source": [
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 22788, 1: 22788})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oversample = SMOTE(random_state=42)\n",
    "X_train, y_train = oversample.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mu, sigma = 0, 0.1 \n",
    "noise = np.random.normal(mu, sigma, [X_train.shape[0],X_train.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train=X_train+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45576, 15)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(15,))\n",
    "encoded=Dense(10, activation='relu')(input_)\n",
    "encoded = Dense(7, activation='relu')(encoded)\n",
    "encoded = Dense(5, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(7, activation='relu')(encoded)\n",
    "decoded = Dense(10, activation='relu')(decoded)\n",
    "decoded = Dense(15)(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "#X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36460 samples, validate on 9116 samples\n",
      "Epoch 1/100\n",
      "36460/36460 [==============================] - 0s 13us/step - loss: 0.9121 - val_loss: 0.9261\n",
      "Epoch 2/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.7799 - val_loss: 0.8114\n",
      "Epoch 3/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.6751 - val_loss: 0.7076\n",
      "Epoch 4/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.5982 - val_loss: 0.6311\n",
      "Epoch 5/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.5589 - val_loss: 0.5916\n",
      "Epoch 6/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.5326 - val_loss: 0.5580\n",
      "Epoch 7/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.5163 - val_loss: 0.5370\n",
      "Epoch 8/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.5034 - val_loss: 0.5215\n",
      "Epoch 9/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4924 - val_loss: 0.5118\n",
      "Epoch 10/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4832 - val_loss: 0.5015\n",
      "Epoch 11/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.4743 - val_loss: 0.4869\n",
      "Epoch 12/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4638 - val_loss: 0.4788\n",
      "Epoch 13/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4552 - val_loss: 0.4654\n",
      "Epoch 14/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4473 - val_loss: 0.4576\n",
      "Epoch 15/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4409 - val_loss: 0.4554\n",
      "Epoch 16/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4375 - val_loss: 0.4484\n",
      "Epoch 17/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4325 - val_loss: 0.4416\n",
      "Epoch 18/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4279 - val_loss: 0.4356\n",
      "Epoch 19/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4229 - val_loss: 0.4338\n",
      "Epoch 20/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4207 - val_loss: 0.4286\n",
      "Epoch 21/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4183 - val_loss: 0.4275\n",
      "Epoch 22/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4166 - val_loss: 0.4254\n",
      "Epoch 23/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4149 - val_loss: 0.4243\n",
      "Epoch 24/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4136 - val_loss: 0.4235\n",
      "Epoch 25/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4133 - val_loss: 0.4232\n",
      "Epoch 26/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4113 - val_loss: 0.4208\n",
      "Epoch 27/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4105 - val_loss: 0.4295\n",
      "Epoch 28/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4093 - val_loss: 0.4204\n",
      "Epoch 29/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4087 - val_loss: 0.4185\n",
      "Epoch 30/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.4074 - val_loss: 0.4203\n",
      "Epoch 31/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.4068 - val_loss: 0.4165\n",
      "Epoch 32/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4050 - val_loss: 0.4155\n",
      "Epoch 33/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4042 - val_loss: 0.4194\n",
      "Epoch 34/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4032 - val_loss: 0.4137\n",
      "Epoch 35/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4021 - val_loss: 0.4114\n",
      "Epoch 36/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.4012 - val_loss: 0.4137\n",
      "Epoch 37/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.4013 - val_loss: 0.4123\n",
      "Epoch 38/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.4004 - val_loss: 0.4112\n",
      "Epoch 39/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3998 - val_loss: 0.4096\n",
      "Epoch 40/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3992 - val_loss: 0.4114\n",
      "Epoch 41/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3989 - val_loss: 0.4125\n",
      "Epoch 42/100\n",
      "36460/36460 [==============================] - 0s 8us/step - loss: 0.3986 - val_loss: 0.4090\n",
      "Epoch 43/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3978 - val_loss: 0.4166\n",
      "Epoch 44/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3977 - val_loss: 0.4128\n",
      "Epoch 45/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3979 - val_loss: 0.4073\n",
      "Epoch 46/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3970 - val_loss: 0.4103\n",
      "Epoch 47/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3972 - val_loss: 0.4092\n",
      "Epoch 48/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3968 - val_loss: 0.4095\n",
      "Epoch 49/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3970 - val_loss: 0.4061\n",
      "Epoch 50/100\n",
      "36460/36460 [==============================] - 0s 8us/step - loss: 0.3960 - val_loss: 0.4050\n",
      "Epoch 51/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3949 - val_loss: 0.4063\n",
      "Epoch 52/100\n",
      "36460/36460 [==============================] - 0s 13us/step - loss: 0.3949 - val_loss: 0.4063\n",
      "Epoch 53/100\n",
      "36460/36460 [==============================] - 0s 13us/step - loss: 0.3955 - val_loss: 0.4074\n",
      "Epoch 54/100\n",
      "36460/36460 [==============================] - 0s 13us/step - loss: 0.3949 - val_loss: 0.4055\n",
      "Epoch 55/100\n",
      "36460/36460 [==============================] - 0s 9us/step - loss: 0.3935 - val_loss: 0.4035\n",
      "Epoch 56/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3947 - val_loss: 0.4057\n",
      "Epoch 57/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3945 - val_loss: 0.4051\n",
      "Epoch 58/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3943 - val_loss: 0.4043\n",
      "Epoch 59/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3938 - val_loss: 0.4037\n",
      "Epoch 60/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3935 - val_loss: 0.4086\n",
      "Epoch 61/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3930 - val_loss: 0.4051\n",
      "Epoch 62/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3930 - val_loss: 0.4028\n",
      "Epoch 63/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3923 - val_loss: 0.4035\n",
      "Epoch 64/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3931 - val_loss: 0.4051\n",
      "Epoch 65/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3920 - val_loss: 0.4079\n",
      "Epoch 66/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3920 - val_loss: 0.4083\n",
      "Epoch 67/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3926 - val_loss: 0.4049\n",
      "Epoch 68/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3918 - val_loss: 0.4019\n",
      "Epoch 69/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3909 - val_loss: 0.4005\n",
      "Epoch 70/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3904 - val_loss: 0.4010\n",
      "Epoch 71/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3904 - val_loss: 0.3999\n",
      "Epoch 72/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3906 - val_loss: 0.3992\n",
      "Epoch 73/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3903 - val_loss: 0.4006\n",
      "Epoch 74/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3905 - val_loss: 0.4004\n",
      "Epoch 75/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3894 - val_loss: 0.4011\n",
      "Epoch 76/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3898 - val_loss: 0.4016\n",
      "Epoch 77/100\n",
      "36460/36460 [==============================] - 0s 7us/step - loss: 0.3895 - val_loss: 0.3987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "36460/36460 [==============================] - 0s 5us/step - loss: 0.3901 - val_loss: 0.3995\n",
      "Epoch 79/100\n",
      "36460/36460 [==============================] - 0s 5us/step - loss: 0.3889 - val_loss: 0.4013\n",
      "Epoch 80/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3886 - val_loss: 0.3987\n",
      "Epoch 81/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3896 - val_loss: 0.3971\n",
      "Epoch 82/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3887 - val_loss: 0.4002\n",
      "Epoch 83/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3890 - val_loss: 0.3992\n",
      "Epoch 84/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3880 - val_loss: 0.3992\n",
      "Epoch 85/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3891 - val_loss: 0.3978\n",
      "Epoch 86/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3886 - val_loss: 0.4017\n",
      "Epoch 87/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3878 - val_loss: 0.3976\n",
      "Epoch 88/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3875 - val_loss: 0.3991\n",
      "Epoch 89/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3884 - val_loss: 0.3980\n",
      "Epoch 90/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3882 - val_loss: 0.3981\n",
      "Epoch 91/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3884 - val_loss: 0.4015\n",
      "Epoch 92/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3877 - val_loss: 0.3999\n",
      "Epoch 93/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3880 - val_loss: 0.3973\n",
      "Epoch 94/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3877 - val_loss: 0.3965\n",
      "Epoch 95/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3880 - val_loss: 0.4001\n",
      "Epoch 96/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3868 - val_loss: 0.3980\n",
      "Epoch 97/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3868 - val_loss: 0.3956\n",
      "Epoch 98/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3862 - val_loss: 0.3948\n",
      "Epoch 99/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3871 - val_loss: 0.3998\n",
      "Epoch 100/100\n",
      "36460/36460 [==============================] - 0s 6us/step - loss: 0.3861 - val_loss: 0.3944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20405a4dcc8>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = Model(input_, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "autoencoder.fit(X_noise_train, X_train_enc,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_noise_test, X_test_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42957382,  0.84580793,  0.96995317, ..., -0.32943023,\n",
       "        -1.16613196,  0.24797815],\n",
       "       [-0.30206943,  1.05838071,  0.95351112, ...,  0.51843461,\n",
       "        -0.92155985,  0.00727624],\n",
       "       [-0.30571745,  0.43408211,  0.39927178, ..., -2.63004387,\n",
       "         1.14027181,  0.00614663],\n",
       "       ...,\n",
       "       [-0.40179805, -1.10967813, -1.20818474, ..., -2.47071054,\n",
       "        -0.44596764,  1.53185444],\n",
       "       [-0.46260539,  0.74601074,  1.13538523, ...,  0.29938039,\n",
       "         1.56809366,  0.13219501],\n",
       "       [-0.4914913 ,  0.78369402,  0.92216642, ...,  0.35016166,\n",
       "        -0.79319732,  0.25067879]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_autoenc=autoencoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20335579,  0.5461263 ,  0.5084764 , ...,  0.32064903,\n",
       "        -0.46795544,  0.28849888],\n",
       "       [ 0.25288785,  1.1874534 ,  1.1792475 , ...,  0.26674068,\n",
       "        -0.48090738,  0.29039964],\n",
       "       [-0.2537887 , -1.5565448 , -1.5694373 , ..., -0.26716575,\n",
       "         0.6160876 ,  0.340685  ],\n",
       "       ...,\n",
       "       [-0.4346274 ,  0.7644179 ,  0.7197113 , ...,  0.17999195,\n",
       "         0.27378428,  0.33125433],\n",
       "       [-0.4324602 ,  0.7629684 ,  0.7810918 , ..., -0.15694113,\n",
       "         0.48834467,  0.19056776],\n",
       "       [-0.3346604 , -1.5629961 , -1.5502673 , ..., -0.17007118,\n",
       "        -0.18967807,  0.06418961]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33602492,  0.97845068,  0.99540677, ..., -0.36835487,\n",
       "        -1.06137057,  0.06382199],\n",
       "       [-0.33602492,  0.99795818,  1.01504978, ...,  0.64365126,\n",
       "        -1.00872781,  0.06382199],\n",
       "       [-0.33602492,  0.31147559,  0.32379842, ..., -2.52905401,\n",
       "         1.13749775,  0.06382199],\n",
       "       ...,\n",
       "       [-0.33602492, -1.1847614 , -1.20713232, ..., -2.43643296,\n",
       "        -0.45440937,  1.49466609],\n",
       "       [-0.33602492,  0.80110665,  0.81683078, ...,  0.24505213,\n",
       "         1.60118818,  0.06382199],\n",
       "       [-0.33602492,  0.99795818,  1.01504978, ...,  0.40900741,\n",
       "        -1.00872781,  0.06382199]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_autoenc,y,test_size=.2)\n",
    "X_val,X_test,y_val,y_test=train_test_split(X_test,y_test,test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36460 samples, validate on 4558 samples\n",
      "Epoch 1/80\n",
      "36460/36460 [==============================] - 1s 27us/step - loss: 0.1518 - recall: 0.0000e+00 - val_loss: 0.7938 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "36460/36460 [==============================] - 1s 24us/step - loss: 0.0918 - recall: 0.3054 - val_loss: 0.5726 - val_recall: 0.5240\n",
      "Epoch 3/80\n",
      "36460/36460 [==============================] - 1s 33us/step - loss: 0.0769 - recall: 0.5936 - val_loss: 0.5106 - val_recall: 0.6448\n",
      "Epoch 4/80\n",
      "36460/36460 [==============================] - 1s 23us/step - loss: 0.0714 - recall: 0.6296 - val_loss: 0.5528 - val_recall: 0.6047\n",
      "Epoch 5/80\n",
      "36460/36460 [==============================] - 1s 23us/step - loss: 0.0703 - recall: 0.6306 - val_loss: 0.4285 - val_recall: 0.6783\n",
      "Epoch 6/80\n",
      "36460/36460 [==============================] - 1s 37us/step - loss: 0.0674 - recall: 0.6427 - val_loss: 0.4423 - val_recall: 0.6602\n",
      "Epoch 7/80\n",
      "36460/36460 [==============================] - 1s 21us/step - loss: 0.0637 - recall: 0.6614 - val_loss: 0.4487 - val_recall: 0.6677\n",
      "Epoch 8/80\n",
      "36460/36460 [==============================] - 1s 22us/step - loss: 0.0621 - recall: 0.6680 - val_loss: 0.4298 - val_recall: 0.7047\n",
      "Epoch 9/80\n",
      "36460/36460 [==============================] - 1s 37us/step - loss: 0.0602 - recall: 0.6782 - val_loss: 0.5254 - val_recall: 0.6390\n",
      "Epoch 10/80\n",
      "36460/36460 [==============================] - 1s 23us/step - loss: 0.0651 - recall: 0.6333 - val_loss: 0.4150 - val_recall: 0.6941\n",
      "Epoch 11/80\n",
      "36460/36460 [==============================] - 1s 21us/step - loss: 0.0618 - recall: 0.6588 - val_loss: 0.4318 - val_recall: 0.6637\n",
      "Epoch 12/80\n",
      "36460/36460 [==============================] - 1s 37us/step - loss: 0.0594 - recall: 0.6618 - val_loss: 0.4357 - val_recall: 0.6606\n",
      "Epoch 13/80\n",
      "36460/36460 [==============================] - 1s 27us/step - loss: 0.0582 - recall: 0.6779 - val_loss: 0.4078 - val_recall: 0.7228\n",
      "Epoch 14/80\n",
      "36460/36460 [==============================] - 1s 24us/step - loss: 0.0575 - recall: 0.6884 - val_loss: 0.4185 - val_recall: 0.6774\n",
      "Epoch 15/80\n",
      "36460/36460 [==============================] - 1s 38us/step - loss: 0.0570 - recall: 0.6852 - val_loss: 0.4095 - val_recall: 0.7109\n",
      "Epoch 16/80\n",
      "36460/36460 [==============================] - 1s 23us/step - loss: 0.0576 - recall: 0.6887 - val_loss: 0.3857 - val_recall: 0.7012\n",
      "Epoch 17/80\n",
      "36460/36460 [==============================] - 1s 31us/step - loss: 0.0572 - recall: 0.6849 - val_loss: 0.4495 - val_recall: 0.6598\n",
      "Epoch 18/80\n",
      "36460/36460 [==============================] - 1s 35us/step - loss: 0.0576 - recall: 0.6785 - val_loss: 0.4086 - val_recall: 0.7012\n",
      "Epoch 19/80\n",
      "36460/36460 [==============================] - 1s 24us/step - loss: 0.0540 - recall: 0.7087 - val_loss: 0.3905 - val_recall: 0.7237\n",
      "Epoch 20/80\n",
      "36460/36460 [==============================] - 1s 35us/step - loss: 0.0533 - recall: 0.7159 - val_loss: 0.3712 - val_recall: 0.7272\n",
      "Epoch 21/80\n",
      "36460/36460 [==============================] - 1s 30us/step - loss: 0.0541 - recall: 0.6996 - val_loss: 0.4036 - val_recall: 0.7052\n",
      "Epoch 22/80\n",
      "36460/36460 [==============================] - 1s 24us/step - loss: 0.0549 - recall: 0.6979 - val_loss: 0.3768 - val_recall: 0.7219\n",
      "Epoch 23/80\n",
      "36460/36460 [==============================] - 1s 38us/step - loss: 0.0531 - recall: 0.7128 - val_loss: 0.4042 - val_recall: 0.7206\n",
      "Epoch 24/80\n",
      "36460/36460 [==============================] - 1s 28us/step - loss: 0.0535 - recall: 0.7086 - val_loss: 0.3721 - val_recall: 0.7276\n",
      "Epoch 25/80\n",
      "36460/36460 [==============================] - 1s 28us/step - loss: 0.0527 - recall: 0.7159 - val_loss: 0.4266 - val_recall: 0.7065\n",
      "Epoch 26/80\n",
      "36460/36460 [==============================] - 1s 38us/step - loss: 0.0561 - recall: 0.6922 - val_loss: 0.3740 - val_recall: 0.7144\n",
      "Epoch 27/80\n",
      "36460/36460 [==============================] - 1s 24us/step - loss: 0.0532 - recall: 0.7040 - val_loss: 0.4178 - val_recall: 0.7007\n",
      "Epoch 28/80\n",
      "36460/36460 [==============================] - 1s 33us/step - loss: 0.0540 - recall: 0.7024 - val_loss: 0.3927 - val_recall: 0.7007\n",
      "Epoch 29/80\n",
      "36460/36460 [==============================] - 1s 31us/step - loss: 0.0532 - recall: 0.7037 - val_loss: 0.3705 - val_recall: 0.7290\n",
      "Epoch 30/80\n",
      "36460/36460 [==============================] - 1s 21us/step - loss: 0.0532 - recall: 0.7052 - val_loss: 0.3659 - val_recall: 0.7228\n",
      "Epoch 31/80\n",
      "36460/36460 [==============================] - 1s 31us/step - loss: 0.0530 - recall: 0.7079 - val_loss: 0.3731 - val_recall: 0.7259\n",
      "Epoch 32/80\n",
      "36460/36460 [==============================] - 1s 31us/step - loss: 0.0513 - recall: 0.7136 - val_loss: 0.3702 - val_recall: 0.7382\n",
      "Epoch 33/80\n",
      "36460/36460 [==============================] - 1s 22us/step - loss: 0.0507 - recall: 0.7230 - val_loss: 0.4087 - val_recall: 0.7188\n",
      "Epoch 34/80\n",
      "36460/36460 [==============================] - 1s 35us/step - loss: 0.0503 - recall: 0.7171 - val_loss: 0.4149 - val_recall: 0.6884\n",
      "Epoch 35/80\n",
      "36460/36460 [==============================] - 1s 27us/step - loss: 0.0518 - recall: 0.7145 - val_loss: 0.3608 - val_recall: 0.7228\n",
      "Epoch 36/80\n",
      "36460/36460 [==============================] - 1s 19us/step - loss: 0.0499 - recall: 0.7169 - val_loss: 0.3681 - val_recall: 0.7268\n",
      "Epoch 37/80\n",
      "36460/36460 [==============================] - 1s 27us/step - loss: 0.0486 - recall: 0.7254 - val_loss: 0.3723 - val_recall: 0.7219\n",
      "Epoch 38/80\n",
      "36460/36460 [==============================] - 1s 30us/step - loss: 0.0503 - recall: 0.7147 - val_loss: 0.3949 - val_recall: 0.6972\n",
      "Epoch 39/80\n",
      "36460/36460 [==============================] - 1s 19us/step - loss: 0.0499 - recall: 0.7206 - val_loss: 0.3845 - val_recall: 0.7149\n",
      "Epoch 40/80\n",
      "36460/36460 [==============================] - 1s 23us/step - loss: 0.0485 - recall: 0.7249 - val_loss: 0.3623 - val_recall: 0.7281\n",
      "Epoch 41/80\n",
      "36460/36460 [==============================] - 1s 33us/step - loss: 0.0488 - recall: 0.7264 - val_loss: 0.3713 - val_recall: 0.7422\n",
      "Epoch 42/80\n",
      "36460/36460 [==============================] - 1s 18us/step - loss: 0.0472 - recall: 0.7427 - val_loss: 0.3542 - val_recall: 0.7307\n",
      "Epoch 43/80\n",
      "36460/36460 [==============================] - 1s 20us/step - loss: 0.0478 - recall: 0.7275 - val_loss: 0.3619 - val_recall: 0.7347\n",
      "Epoch 44/80\n",
      "36460/36460 [==============================] - 1s 33us/step - loss: 0.0481 - recall: 0.7311 - val_loss: 0.3587 - val_recall: 0.7378\n",
      "Epoch 45/80\n",
      "36460/36460 [==============================] - 1s 22us/step - loss: 0.0484 - recall: 0.7238 - val_loss: 0.3369 - val_recall: 0.7439\n",
      "Epoch 46/80\n",
      "36460/36460 [==============================] - 1s 19us/step - loss: 0.0480 - recall: 0.7261 - val_loss: 0.3657 - val_recall: 0.7201\n",
      "Epoch 47/80\n",
      "36460/36460 [==============================] - 1s 26us/step - loss: 0.0471 - recall: 0.7347 - val_loss: 0.3578 - val_recall: 0.7215\n",
      "Epoch 48/80\n",
      "36460/36460 [==============================] - 1s 30us/step - loss: 0.0462 - recall: 0.7337 - val_loss: 0.4051 - val_recall: 0.7223\n",
      "Epoch 49/80\n",
      "36460/36460 [==============================] - 1s 18us/step - loss: 0.0469 - recall: 0.7334 - val_loss: 0.3542 - val_recall: 0.7431\n",
      "Epoch 50/80\n",
      "36460/36460 [==============================] - 1s 22us/step - loss: 0.0466 - recall: 0.7340 - val_loss: 0.3666 - val_recall: 0.7439\n",
      "Epoch 51/80\n",
      "36460/36460 [==============================] - 1s 34us/step - loss: 0.0479 - recall: 0.7260 - val_loss: 0.3560 - val_recall: 0.7483\n",
      "Epoch 52/80\n",
      "36460/36460 [==============================] - 1s 21us/step - loss: 0.0480 - recall: 0.7382 - val_loss: 0.3807 - val_recall: 0.7210\n",
      "Epoch 53/80\n",
      "36460/36460 [==============================] - 1s 21us/step - loss: 0.0485 - recall: 0.7242 - val_loss: 0.3725 - val_recall: 0.7078\n",
      "Epoch 54/80\n",
      "36460/36460 [==============================] - 1s 36us/step - loss: 0.0469 - recall: 0.7463 - val_loss: 0.3702 - val_recall: 0.7572\n",
      "Epoch 55/80\n",
      "36460/36460 [==============================] - 1s 40us/step - loss: 0.0484 - recall: 0.7298 - val_loss: 0.3649 - val_recall: 0.7228\n",
      "Epoch 56/80\n",
      "36460/36460 [==============================] - 1s 29us/step - loss: 0.0474 - recall: 0.7234 - val_loss: 0.3542 - val_recall: 0.7488\n",
      "Epoch 57/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36460/36460 [==============================] - 1s 22us/step - loss: 0.0458 - recall: 0.7483 - val_loss: 0.3089 - val_recall: 0.7752\n",
      "Epoch 58/80\n",
      "36460/36460 [==============================] - 1s 34us/step - loss: 0.0457 - recall: 0.7458 - val_loss: 0.3381 - val_recall: 0.7413\n",
      "Epoch 59/80\n",
      "36460/36460 [==============================] - 1s 28us/step - loss: 0.0447 - recall: 0.7527 - val_loss: 0.3478 - val_recall: 0.7532\n",
      "Epoch 60/80\n",
      "36460/36460 [==============================] - 1s 24us/step - loss: 0.0458 - recall: 0.7467 - val_loss: 0.3694 - val_recall: 0.7131\n",
      "Epoch 61/80\n",
      "36460/36460 [==============================] - 1s 39us/step - loss: 0.0462 - recall: 0.7319 - val_loss: 0.3406 - val_recall: 0.7461\n",
      "Epoch 62/80\n",
      "36460/36460 [==============================] - 1s 25us/step - loss: 0.0449 - recall: 0.7483 - val_loss: 0.3438 - val_recall: 0.7488\n",
      "Epoch 63/80\n",
      "36460/36460 [==============================] - 1s 23us/step - loss: 0.0451 - recall: 0.7455 - val_loss: 0.3573 - val_recall: 0.7431\n",
      "Epoch 64/80\n",
      "36460/36460 [==============================] - 1s 40us/step - loss: 0.0448 - recall: 0.7478 - val_loss: 0.3185 - val_recall: 0.7664\n",
      "Epoch 65/80\n",
      "36460/36460 [==============================] - 1s 37us/step - loss: 0.0428 - recall: 0.7588 - val_loss: 0.3312 - val_recall: 0.7717\n",
      "Epoch 66/80\n",
      "36460/36460 [==============================] - 1s 28us/step - loss: 0.0431 - recall: 0.7552 - val_loss: 0.3573 - val_recall: 0.7404\n",
      "Epoch 67/80\n",
      "36460/36460 [==============================] - 1s 27us/step - loss: 0.0478 - recall: 0.7342 - val_loss: 0.3664 - val_recall: 0.7228\n",
      "Epoch 68/80\n",
      "36460/36460 [==============================] - 1s 38us/step - loss: 0.0454 - recall: 0.7402 - val_loss: 0.3295 - val_recall: 0.7616\n",
      "Epoch 69/80\n",
      "36460/36460 [==============================] - 1s 23us/step - loss: 0.0436 - recall: 0.7516 - val_loss: 0.3435 - val_recall: 0.7470\n",
      "Epoch 70/80\n",
      "36460/36460 [==============================] - 1s 28us/step - loss: 0.0428 - recall: 0.7592 - val_loss: 0.3614 - val_recall: 0.7241\n",
      "Epoch 71/80\n",
      "36460/36460 [==============================] - 1s 39us/step - loss: 0.0438 - recall: 0.7487 - val_loss: 0.3254 - val_recall: 0.7638\n",
      "Epoch 72/80\n",
      "36460/36460 [==============================] - 1s 38us/step - loss: 0.0431 - recall: 0.7515 - val_loss: 0.3208 - val_recall: 0.7620\n",
      "Epoch 73/80\n",
      "36460/36460 [==============================] - 1s 24us/step - loss: 0.0427 - recall: 0.7597 - val_loss: 0.3432 - val_recall: 0.7479\n",
      "Epoch 74/80\n",
      "36460/36460 [==============================] - 1s 29us/step - loss: 0.0425 - recall: 0.7559 - val_loss: 0.3253 - val_recall: 0.7832\n",
      "Epoch 75/80\n",
      "36460/36460 [==============================] - 1s 36us/step - loss: 0.0439 - recall: 0.7546 - val_loss: 0.3176 - val_recall: 0.7686\n",
      "Epoch 76/80\n",
      "36460/36460 [==============================] - 1s 38us/step - loss: 0.0427 - recall: 0.7599 - val_loss: 0.3373 - val_recall: 0.7629\n",
      "Epoch 77/80\n",
      "36460/36460 [==============================] - 1s 22us/step - loss: 0.0437 - recall: 0.7543 - val_loss: 0.3524 - val_recall: 0.7558\n",
      "Epoch 78/80\n",
      "36460/36460 [==============================] - 1s 21us/step - loss: 0.0425 - recall: 0.7629 - val_loss: 0.3798 - val_recall: 0.7272\n",
      "Epoch 79/80\n",
      "36460/36460 [==============================] - 1s 38us/step - loss: 0.0421 - recall: 0.7615 - val_loss: 0.3089 - val_recall: 0.7788\n",
      "Epoch 80/80\n",
      "36460/36460 [==============================] - 1s 37us/step - loss: 0.0474 - recall: 0.7388 - val_loss: 0.3822 - val_recall: 0.7373\n"
     ]
    }
   ],
   "source": [
    "seq=Sequential()\n",
    "seq.add(Dense(256,activation=activations.relu,input_shape=(15,),name='layer1'))\n",
    "#seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer2'))\n",
    "#seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer3'))\n",
    "#seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer4'))\n",
    "#seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer5'))\n",
    "#seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(256,activation='relu',name='layer6'))\n",
    "#seq.add(Dense(128,activation='relu',name='layer7'))\n",
    "#seq.add(Dense(64,activation='relu',name='layer8'))\n",
    "#seq.add(Dense(32,activation='relu',name='layer9'))\n",
    "#seq.add(layers.Dropout(0.3))\n",
    "seq.add(Dense(1,activation='sigmoid',name='layer10'))\n",
    "metrics=[keras.metrics.Recall(name=\"recall\")]\n",
    "\n",
    "seq.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics)\n",
    "class_weight = {0: .5, 1: .1}\n",
    "\n",
    "#history=seq.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=50,batch_size=1024)\n",
    "history=seq.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=80,batch_size=2048,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_enc=autoencoder.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn_pred_score=seq.predict(df_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn_pred=y_nn_pred_score>.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn_Pred=y_nn_pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn_Pred=seq.predict_classes(df_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_nn_Pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33602492,  0.73548947,  0.61861178, ...,  0.24505213,\n",
       "        -1.00872781,  0.30229601],\n",
       "       [ 0.35856051,  0.80110665,  0.81683078, ...,  0.64365126,\n",
       "         1.60118818,  0.06382199],\n",
       "       [-0.33602492, -1.42987743, -1.4957242 , ...,  0.89730526,\n",
       "         0.46945469,  0.06382199],\n",
       "       ...,\n",
       "       [-0.33602492,  0.73548947,  0.61861178, ...,  0.24505213,\n",
       "         1.26962802,  0.30229601],\n",
       "       [-0.33602492,  1.21038343,  1.22895067, ..., -0.47967357,\n",
       "         0.29642753,  0.31644598],\n",
       "       [-0.33602492, -1.36426025, -1.3635782 , ...,  0.02212672,\n",
       "        -0.60277466,  0.06382199]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_nn_score=seq.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.6774176e-05],\n",
       "       [4.6114441e-02],\n",
       "       [9.7914451e-01],\n",
       "       ...,\n",
       "       [3.1450582e-01],\n",
       "       [4.2265574e-03],\n",
       "       [1.4983720e-01]], dtype=float32)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_nn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_test_nn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8317962231005709"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33149102,  0.3465487 ,  0.68916296, ..., -0.47981008,\n",
       "         1.07699829, -1.25362   ],\n",
       "       [-0.33149102,  1.26588593,  1.28412657, ..., -2.66223712,\n",
       "        -0.99497464,  0.06944597],\n",
       "       [-0.33149102,  0.60921648,  0.55694882, ..., -0.47981008,\n",
       "        -1.66261037,  0.06944597],\n",
       "       ...,\n",
       "       [-0.33149102,  0.08388092,  0.16030642, ..., -0.47981008,\n",
       "        -0.23525123,  0.06944597],\n",
       "       [-0.33149102, -0.2444538 , -0.10412185, ...,  0.2476656 ,\n",
       "        -0.23525123,  0.06944597],\n",
       "       [-0.33149102, -1.36079186, -1.36015614, ..., -0.47981008,\n",
       "        -0.99497464,  0.06944597]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict={'INCIDENT_ID':test_inident_id,'MULTIPLE_OFFENSE':y_nn_Pred[:,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload=pd.DataFrame(data=datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>MULTIPLE_OFFENSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR_195453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CR_103520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CR_196089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CR_112195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CR_149832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15898</th>\n",
       "      <td>CR_44468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15899</th>\n",
       "      <td>CR_158460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15900</th>\n",
       "      <td>CR_115946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15901</th>\n",
       "      <td>CR_137663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15902</th>\n",
       "      <td>CR_33545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15903 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      INCIDENT_ID  MULTIPLE_OFFENSE\n",
       "0       CR_195453                 1\n",
       "1       CR_103520                 1\n",
       "2       CR_196089                 1\n",
       "3       CR_112195                 1\n",
       "4       CR_149832                 1\n",
       "...           ...               ...\n",
       "15898    CR_44468                 1\n",
       "15899   CR_158460                 1\n",
       "15900   CR_115946                 1\n",
       "15901   CR_137663                 1\n",
       "15902    CR_33545                 1\n",
       "\n",
       "[15903 rows x 2 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload.to_csv(\"hacking_incidence_NN1.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
