{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:\\\\Users\\\\shsubham\\\\program\\\\DATA\\\\hackerearth\\\\planecrash\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_Severity=LabelEncoder()\n",
    "le_Severity.fit(df['Severity'])\n",
    "df['Severity']=le_Severity.transform(df['Severity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop([\"Severity\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[\"Severity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['Accident_ID','Accident_Type_Code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss=StandardScaler()\n",
    "#X=ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=MinMaxScaler()\n",
    "X=mm.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.hist(figsize=(20,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shsubham\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#model.add(keras.layers.Flatten(9))\n",
    "model.add(keras.layers.Dense(units=300,activation='relu',input_shape=X_train.shape[1:]))\n",
    "#model.add(keras.layers.Dense(100,activation='relu'))\n",
    "model.add(keras.layers.Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_,X_test,y_,y_test=train_test_split(X,y,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_holdout,y_train,y_holdout=train_test_split(X_,y_,test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np=np.array(X_train)\n",
    "y_train_np=np.array(y_train)\n",
    "X_holdout_np=np.array(X_holdout)\n",
    "y_holdout_np=np.array(y_holdout)\n",
    "X_test_np=np.array(X_test)\n",
    "y_test_np=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/30\n",
      "6000/6000 [==============================] - 2s 336us/sample - loss: 1.3643 - acc: 0.3072 - val_loss: 1.3544 - val_acc: 0.3210\n",
      "Epoch 2/30\n",
      "6000/6000 [==============================] - 0s 68us/sample - loss: 1.3548 - acc: 0.3078 - val_loss: 1.3482 - val_acc: 0.3180\n",
      "Epoch 3/30\n",
      "6000/6000 [==============================] - 0s 70us/sample - loss: 1.3487 - acc: 0.3180 - val_loss: 1.3429 - val_acc: 0.3200\n",
      "Epoch 4/30\n",
      "6000/6000 [==============================] - 0s 71us/sample - loss: 1.3429 - acc: 0.3348 - val_loss: 1.3383 - val_acc: 0.3650\n",
      "Epoch 5/30\n",
      "6000/6000 [==============================] - 0s 69us/sample - loss: 1.3372 - acc: 0.3447 - val_loss: 1.3330 - val_acc: 0.3615\n",
      "Epoch 6/30\n",
      "6000/6000 [==============================] - 0s 69us/sample - loss: 1.3316 - acc: 0.3515 - val_loss: 1.3292 - val_acc: 0.4005\n",
      "Epoch 7/30\n",
      "6000/6000 [==============================] - 0s 69us/sample - loss: 1.3263 - acc: 0.3858 - val_loss: 1.3228 - val_acc: 0.3660\n",
      "Epoch 8/30\n",
      "6000/6000 [==============================] - 0s 83us/sample - loss: 1.3213 - acc: 0.3738 - val_loss: 1.3183 - val_acc: 0.3775\n",
      "Epoch 9/30\n",
      "6000/6000 [==============================] - 0s 68us/sample - loss: 1.3160 - acc: 0.3793 - val_loss: 1.3136 - val_acc: 0.3955\n",
      "Epoch 10/30\n",
      "6000/6000 [==============================] - 0s 70us/sample - loss: 1.3108 - acc: 0.3972 - val_loss: 1.3088 - val_acc: 0.3915\n",
      "Epoch 11/30\n",
      "6000/6000 [==============================] - 0s 69us/sample - loss: 1.3056 - acc: 0.4007 - val_loss: 1.3042 - val_acc: 0.3985\n",
      "Epoch 12/30\n",
      "6000/6000 [==============================] - 1s 103us/sample - loss: 1.3005 - acc: 0.4015 - val_loss: 1.2997 - val_acc: 0.4175\n",
      "Epoch 13/30\n",
      "6000/6000 [==============================] - 0s 83us/sample - loss: 1.2954 - acc: 0.4112 - val_loss: 1.2946 - val_acc: 0.4030\n",
      "Epoch 14/30\n",
      "6000/6000 [==============================] - 0s 69us/sample - loss: 1.2902 - acc: 0.4092 - val_loss: 1.2902 - val_acc: 0.4130\n",
      "Epoch 15/30\n",
      "6000/6000 [==============================] - 0s 70us/sample - loss: 1.2852 - acc: 0.4172 - val_loss: 1.2855 - val_acc: 0.4065\n",
      "Epoch 16/30\n",
      "6000/6000 [==============================] - 0s 72us/sample - loss: 1.2800 - acc: 0.4177 - val_loss: 1.2804 - val_acc: 0.4405\n",
      "Epoch 17/30\n",
      "6000/6000 [==============================] - 0s 68us/sample - loss: 1.2753 - acc: 0.4385 - val_loss: 1.2757 - val_acc: 0.4140\n",
      "Epoch 18/30\n",
      "6000/6000 [==============================] - 0s 70us/sample - loss: 1.2701 - acc: 0.4308 - val_loss: 1.2713 - val_acc: 0.4370\n",
      "Epoch 19/30\n",
      "6000/6000 [==============================] - 0s 75us/sample - loss: 1.2650 - acc: 0.4397 - val_loss: 1.2657 - val_acc: 0.4365\n",
      "Epoch 20/30\n",
      "6000/6000 [==============================] - 0s 67us/sample - loss: 1.2602 - acc: 0.4412 - val_loss: 1.2614 - val_acc: 0.4490\n",
      "Epoch 21/30\n",
      "6000/6000 [==============================] - 0s 78us/sample - loss: 1.2552 - acc: 0.4520 - val_loss: 1.2567 - val_acc: 0.4540\n",
      "Epoch 22/30\n",
      "6000/6000 [==============================] - 0s 69us/sample - loss: 1.2503 - acc: 0.4538 - val_loss: 1.2521 - val_acc: 0.4705\n",
      "Epoch 23/30\n",
      "6000/6000 [==============================] - 0s 75us/sample - loss: 1.2452 - acc: 0.4627 - val_loss: 1.2463 - val_acc: 0.4445\n",
      "Epoch 24/30\n",
      "6000/6000 [==============================] - 1s 109us/sample - loss: 1.2405 - acc: 0.4620 - val_loss: 1.2418 - val_acc: 0.4640\n",
      "Epoch 25/30\n",
      "6000/6000 [==============================] - 2s 316us/sample - loss: 1.2353 - acc: 0.4660 - val_loss: 1.2381 - val_acc: 0.4925\n",
      "Epoch 26/30\n",
      "6000/6000 [==============================] - 2s 284us/sample - loss: 1.2305 - acc: 0.4840 - val_loss: 1.2322 - val_acc: 0.4575\n",
      "Epoch 27/30\n",
      "6000/6000 [==============================] - 2s 265us/sample - loss: 1.2257 - acc: 0.4827 - val_loss: 1.2274 - val_acc: 0.4715\n",
      "Epoch 28/30\n",
      "6000/6000 [==============================] - 1s 121us/sample - loss: 1.2205 - acc: 0.4912 - val_loss: 1.2233 - val_acc: 0.4475\n",
      "Epoch 29/30\n",
      "6000/6000 [==============================] - 0s 58us/sample - loss: 1.2163 - acc: 0.4845 - val_loss: 1.2173 - val_acc: 0.4795\n",
      "Epoch 30/30\n",
      "6000/6000 [==============================] - 0s 61us/sample - loss: 1.2113 - acc: 0.4920 - val_loss: 1.2136 - val_acc: 0.5195\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_np,y_train_np,epochs=30,validation_data=(X_holdout_np,y_holdout_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predict=model.predict_classes(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45765603607676975"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,nn_predict,average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
